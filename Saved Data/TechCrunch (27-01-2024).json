{
  "source": "TechCrunch",
  "date": "2024-01-27",
  "no_of_articles": 5,
  "articles": [
    {
      "title": "Can AI do ugly?",
      "content": "\nW\nelcome to the TechCrunch Exchange, a weekly startups-and-markets newsletter. It’s inspired by the daily TechCrunch+ column where it gets its name. Want it in your inbox every Saturday? Sign up here.\nThis week, some thoughts on AI aesthetics, the challenge of uninsurability, and how to pitch a biotech startup to non-experts. — Anna\nToo good to be true\nMost tools claiming to detect AI-generated text fail spectacularly, my colleague Kyle Wiggers reported. That’s a paradox. I’m only human, but a lot of the AI-written pitches I receive don’t pass the sniff test yet; their style and wordiness feel off.\nThen again, it is probably too early to expect machines to detect a je ne sais quoi, even if we can see it. As fellow TechCrunch writer Ron Miller observed recently, “it’s really like AI-generated art, which has a certain look and feel.”\nThat look and feel was made funnily obvious in a recent experiment conducted on one of my favorite social media accounts, Ugly Belgian Houses.\n ",
      "link": "https://techcrunch.com/2024/01/27/ai-versus-reality/",
      "category": "artificial-intelligence",
      "revised_title": "AI's Struggle with Aesthetics: Challenges in Detecting AI-Generated Text and Creating Visually Appealing AI Art",
      "Summary": "- AI-generated text detection tools often fail to accurately identify AI-written content.\n- AI-generated text often has a distinct style and wordiness that can be noticeable to humans.\n- AI-generated art also has a recognizable look and feel, which was highlighted in an experiment conducted on the social media account Ugly Belgian Houses.\n- It may be too early to expect machines to reliably detect AI-generated content, as they may not be able to identify the subtle nuances that humans can.\n- The challenge of detecting AI-generated content is similar to the challenge of detecting AI-generated art."
    },
    {
      "title": "Deal Dive: Can AI fix lost and found?",
      "content": "\nLosing stuff sucks. It’s even more frustrating when something isn’t really lost, but rather left behind in a location, like an airport or sports stadium, which makes it hard to get back. My friend Caitlin knows this all too well; she’s yet to be reunited with the phone she lost at Oktoberfest on September 27, despite confirming in November that they have it.\nWhile Oktoberfest is a more extreme example, people leave a lot of things behind in hotels, on transportation and at events. For example, the MTA transit system in New York collected more than 18,000 lost items from 2018 to 2023 — and that time includes when people were sheltering in place for the pandemic. Boomerang thinks AI can fix lost and found.\nThe Miami-based startup built software that uses machine learning to match pictures and descriptions of lost items. Customers, which can range from gyms to theme parks, upload pictures and descriptions of their lost and found while consumers do the same for the item they’ve lost. If there is a match, consumers can choose to pick up their items or have them shipped.\nThis model hopes to get consumers their items back faster while replacing the current system of people calling customer service desk phone lines repeatedly for updates on their items, according to Boomerang co-founder and CEO Skyler Logsdon. ",
      "link": "https://techcrunch.com/2024/01/27/can-ai-fix-lost-and-found/",
      "category": "artificial-intelligence",
      "revised_title": "AI-Powered Solution Aims to Revolutionize Lost and Found Services",
      "Summary": "- People often lose items in public places like airports, sports stadiums, and hotels.\n- The MTA transit system in New York collected over 18,000 lost items from 2018 to 2023.\n- Boomerang, a Miami-based startup, has developed software that uses AI to match pictures and descriptions of lost items.\n- Customers upload pictures and descriptions of their lost and found items, while consumers do the same for the items they've lost.\n- If there is a match, consumers can choose to pick up their items or have them shipped."
    },
    {
      "title": "How can venture capital survive a three-year liquidity drop?",
      "content": "\n\nListen here or wherever you get your podcasts.\nHello, and welcome back to Equity, the podcast about the business of startups, where we unpack the numbers and nuance behind the headlines.\nThis is our interview show, where we sit down with interesting, knowledgeable folks and dive deep into their favorite topics. For this weekend’s Special Equity Edition, we invited Gené Teare to come back on the podcast. Longtime listeners will recall that we’ve had Gené on a time or two to chat venture capital data with us, and she’s back to do the same this week!\nYep, we’re back to dig into Q4 2023 venture capital results and what’s coming up this year. For backing data, here’s Gené’s Crunchbase News author archive, and here are a few posts that I have put out on the same set of topics.\n\nThe global venture capital market is not done retreating yet\n\nOn the show we looked into stages, sectors — including both AI and web3 — and where we are seeing both weakness and strength. Gené was a treat to have on the show, and we’ll have her back this year as 2024 comes into sharper focus.\nEquity is back on Monday, so see you in a couple days!\n\n\n\n\n\n\n\n\nFor episode transcripts and more, head to Equity’s Simplecast website.\nEquity drops at 7 a.m. PT every Monday, Wednesday and Friday, so subscribe to us on Apple Podcasts, Overcast, Spotify and all the casts. TechCrunch also has a great show on crypto, a show that interviews founders and more!\n\n\n\n\n\n\n\n\n",
      "link": "https://techcrunch.com/2024/01/27/how-can-venture-capital-survive-a-three-year-liquidity-drop/",
      "category": "artificial-intelligence",
      "revised_title": "Venture Capital's Resilience in the Face of a Three-Year Liquidity Decline: Insights from Gené Teare",
      "Summary": "- Equity, a podcast about the business of startups, interviewed Gené Teare to discuss Q4 2023 venture capital results and upcoming trends.\n\n- The global venture capital market is still in retreat, with funding amounts and deal counts declining in Q4 2023 compared to previous quarters.\n\n- Early-stage startups were hit particularly hard, with seed-stage funding down 50% year-over-year.\n\n- Artificial intelligence (AI) and Web3 were among the few sectors that saw increased funding in Q4 2023.\n\n- Gené Teare will return to the podcast later in 2024 to discuss venture capital trends as the year progresses."
    },
    {
      "title": "Critical 2024 AI policy blueprint: Unlocking potential and safeguarding against workplace risks",
      "content": "\n\n\n\n\nRichard Marcus\nContributor\n\n\n\n\t\tRichard Marcus is the head of information security at AuditBoard.\t\n\nMany have described 2023 as the year of AI, and the term made several “word of the year” lists. While it has positively impacted productivity and efficiency in the workplace, AI has also presented a number of emerging risks for businesses.\nFor example, a recent Harris Poll survey commissioned by AuditBoard revealed that roughly half of employed Americans (51%) currently use AI-powered tools for work, undoubtedly driven by ChatGPT and other generative AI solutions. At the same time, however, nearly half (48%) said they enter company data into AI tools not supplied by their business to aid them in their work.\nThis rapid integration of generative AI tools at work presents ethical, legal, privacy, and practical challenges, creating a need for businesses to implement new and robust policies surrounding generative AI tools. As it stands, most have yet to do so — a recent Gartner survey revealed that more than half of organizations lack an internal policy on generative AI, and the Harris Poll found that just 37% of employed Americans have a formal policy regarding the use of non-company-supplied AI-powered tools.\nWhile it may sound like a daunting task, developing a set of policies and standards now can save organizations from major headaches down the road.\nAI use and governance: Risks and challenges\n \n\n\t\t\tDeveloping a set of policies and standards now can save organizations from major headaches down the road.\t\t\t\t\t\n\nGenerative AI’s rapid adoption has made keeping pace with AI risk management and governance difficult for businesses, and there is a distinct disconnect between adoption and formal policies. The previously mentioned Harris Poll found that 64% perceive AI tool usage as safe, indicating that many workers and organizations could be overlooking risks.\nThese risks and challenges can vary, but three of the most common include:\n\nOverconfidence. The Dunning–Kruger effect is a bias that occurs when our own knowledge or abilities are overestimated. We’ve seen this manifest itself relative to AI usage; many overestimate the capabilities of AI without understanding its limitations. This could produce relatively harmless results, such as providing incomplete or inaccurate output, but it could also lead to much more serious situations, such as output that violates legal usage restrictions or creates intellectual property risk.\nSecurity and privacy. AI needs access to large amounts of data for full effectiveness, but this sometimes includes personal data or other sensitive information. There are inherent risks that come along with using unvetted AI tools, so organizations must ensure they’re using tools that meet their data security standards. ",
      "link": "https://techcrunch.com/2024/01/27/critical-2024-ai-policy-blueprint-unlocking-potential-and-safeguarding-against-workplace-risks/",
      "category": "artificial-intelligence",
      "revised_title": "2024 AI Policy Blueprint: Balancing Potential and Mitigating Workplace Risks",
      "Summary": "- Generative AI tools are rapidly being adopted in the workplace, with 51% of employed Americans using them.\n- However, only 37% of employed Americans have a formal policy regarding the use of non-company-supplied AI-powered tools.\n- Common risks and challenges associated with AI use include overconfidence, security and privacy concerns, and the potential for bias and discrimination.\n- Organizations need to implement new and robust policies surrounding generative AI tools to mitigate these risks.\n- Developing a set of policies and standards now can save organizations from major headaches down the road."
    },
    {
      "title": "Disney’s VR treadmill, OpenAI fixes ‘lazy’ GPT-4, and Apple rolls out stolen device protection",
      "content": "\nHey, folks, and welcome to Week in Review (WiR), TechCrunch’s regular newsletter covering notable happenings in tech over the past few days.\nOn the agenda for this edition is Disney’s innovative VR treadmill, OpenAI fixing its “lazy” AI and MIT’s high-capacity, fast-charging organic battery tech. We also cover Apple’s new stolen device protection feature, AI startup Rabbit’s nifty hardware and app makers debating launching apps tailor-made for Apple’s Vision Pro headset.\nThere’s a decent chunk of news to recap this week, so let’s get to it. But first, a reminder to sign up here to receive WiR in your inbox every Saturday if you haven’t already done so.\nNews\nDisney’s VR treadmill: Disney has developed a treadmill-like system for VR composed of hundreds of small, round “tiles” that look to be about the size of a silver dollar, Brian writes. Each serve as a kind of mini, omnidirectional treadmill.\nOpenAI fixes GPT-4: OpenAI dropped prices on a number of AI models this week as it rolled out a fix for its “lazy” GPT-4 models that refused to work — and launched new models for specific use cases.\nApple’s new device protection: Romain writes about Apple’s new stolen device protection feature, which, when turned on, requires Face ID or Touch ID biometric authentication for some actions, like accessing stored passwords and credit cards.\nVision Pro apps a maybe: After Netflix said it wouldn’t release a dedicated app for the Apple Vision Pro, other app makers, including YouTube, are following in its footsteps. The trend doesn’t bode well, necessarily.\nAnalysis\nRabbit’s r1: AI startup Rabbit is developing what Darrell believes is a better vision of the future than the Apple Vision Pro. The r1 can purportedly do what a typical smartphone can do — but using generative AI and natural language.\nPodcasts\nOn Equity, the crew talked about Plural VC announcing a new fund, Fantuan teaming up with Chowbus, Vroom leaving the car-selling business and what’s happening over at Brex.\nMeanwhile, Found featured Ben Goodwin, the co-founder and CEO of Olipop, the gut-healthy soda brand that amassed $200 million in gross sales just five years after its launch.\nAnd Chain Reaction had Anatoly Yakovenko, co-founder of Solana Labs, on the pod. Solana aims to help grow the ecosystem for the layer-1 blockchain Solana.\nTechCrunch+\nTC+ subscribers get access to in-depth commentary, analysis and surveys — which you know if you’re already a subscriber. If you’re not, consider signing up. Here are a few highlights from this week:\nThe tech layoff surge: Alex and Anna write about the surge in staff cuts at tech startups in recent weeks, which flipped the script on expectations for this year.\nHPE’s deal for Juniper: Ron and Alex weigh in on HPE’s decision to buy Juniper Networks a few weeks back for $14 billion. The gist is, the companies think the numbers look pretty good — and they really do match up well (so long as HPE doesn’t mess it up).\nFintech, down but not out: Fintech has been in the dumps for a while now, and with companies like Brex once again cutting staff as they try to rein in costs, you’d be forgiven for assuming that the market for fintech products is struggling. But that isn’t necessarily the case, Alex and Anna write.\nBonus round\nLamborghini licenses MIT battery tech: Writing for TechCrunch+, Tim reports that Lamborghini has licensed new battery tech from MIT that could overcome the limitations of the lithium-ion batteries in wide use today.\n",
      "link": "https://techcrunch.com/2024/01/27/disneys-vr-treadmill-openai-fixes-lazy-gpt-4-and-apple-rolls-out-stolen-device-protection/",
      "category": "social",
      "revised_title": "Weekly Tech Roundup: Disney's VR Treadmill, OpenAI's GPT-4 Fix, and Apple's Stolen Device Protection",
      "Summary": "- Disney has developed a VR treadmill system composed of small, round tiles that serve as mini, omnidirectional treadmills.\n- OpenAI has fixed its \"lazy\" GPT-4 models and launched new models for specific use cases.\n- Apple has introduced a new stolen device protection feature that requires biometric authentication for certain actions.\n- App makers are debating whether to launch apps tailor-made for Apple's Vision Pro headset, with some, like Netflix and YouTube, opting not to.\n- AI startup Rabbit is developing a device called the r1, which can purportedly perform smartphone tasks using generative AI and natural language."
    }
  ]
}